input {
  kafka {
    bootstrap_servers => "kafka-1:9092,kafka-2:9092"  # Kafka brokers
    topics => ["stock-events", "payment-events"]  # List of Kafka topics
    group_id => "ms-logstash-group"  # Consumer group ID
    auto_offset_reset => "earliest"  # Start reading from the earliest message if no offset exists
    codec => "json"  # Optional: Use JSON codec if your data is in JSON format
  }
}

filter {
  mutate {
    add_field => { "source_topic" => "%{[kafka][topic]}" }  # Add the Kafka topic name as a new field
  }
}

output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "generic_index-%{+YYYY.MM.dd}"  # All data goes to the same index with date-based suffix
    document_id => "%{[@metadata][kafka][offset]}"  # Optional: Use Kafka offset as document ID to prevent duplicates
  }

  # Optional: To output to stdout for debugging purposes
  stdout {
    codec => rubydebug
  }
}